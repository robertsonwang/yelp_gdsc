{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare necessary modules/links/directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import scrapping_functions as sf\n",
    "reload(sf)\n",
    "from selenium import webdriver\n",
    "#Start = signifies the listing to start it, increases in increments of 10 per page\n",
    "#End = 990\n",
    "target_url = 'https://www.yelp.com/search?find_desc=Restaurants&find_loc=Washington+DC&start='\n",
    "base = 'https://www.yelp.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pull in a list of links from the target url\n",
    "link_list = []\n",
    "for x in range(507, 991):\n",
    "    target = target_url + str(x)\n",
    "    raw_html = requests.get(target)\n",
    "    soup = BeautifulSoup(raw_html.text, 'html.parser')\n",
    "    link_list = sf.biz_links(soup, link_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Remove extraneous links, keep only business links\n",
    "for link in link_list:\n",
    "    if re.search(\"adredir\", link):\n",
    "        link_list.pop(link_list.index(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write all links to a text file\n",
    "biz_links = open('cleanbiz_links_2.txt', 'w')\n",
    "for item in link_list:\n",
    "    biz_links.write(\"%s\\n\" % item)\n",
    "biz_links.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to construct the following dictionary:\n",
    "\n",
    "biz_dict = {biz_name: {\"city\": \"Washington\", \"state\": \"DC\", \"category_aliases\": \"newamerican,breakfast_brunch\", \"biz_id\": \"wO-7cBBOYUdiLflpuRsu9A\", \"latitude\": 38.90842, \"biz_name\": \"The Bird\", \"city_state\": \"Washington, DC\", \"longitude\": -77.026685, \"geoquad\": 12845454}}\n",
    "\n",
    "unique_id = 5D32F13B349CE2AD\n",
    "\n",
    "#### Algorithm design:\n",
    "\n",
    "For each link in biz_links:\n",
    "    > set biz_name = replace(\"_\", '-' in link)\n",
    "    > find the unique_id\n",
    "    > assign biz_dict[biz_name] = dictionary(biz_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "link_file = open(\"cleanbiz_links.txt\", \"r\")\n",
    "link_list = link_file.read().split('\\n')\n",
    "link_list = list(set(link_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# raw_html = requests.get(base + link_list[0])\n",
    "# soup = BeautifulSoup(raw_html.text, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "biz_dict = {}\n",
    "\n",
    "for link in link_list:\n",
    "    biz_name = link.replace('?osq=Restaurants', '')\n",
    "    biz_name = re.sub(\"-washington*\", '', biz_name)\n",
    "    biz_dict[biz_name] = {}\n",
    "    \n",
    "    raw_html = requests.get(base + link)\n",
    "    soup = BeautifulSoup(raw_html.text, 'html.parser')\n",
    "    parse_string = str(soup.find_all(\"script\"))\n",
    "    parse_list = parse_string.split('<script>')\n",
    "    \n",
    "    try:\n",
    "        match = re.sub(\".*,null,\",'', [s for s in parse_list if re.search(\".*latitude.*\", s)][0])\n",
    "    except IndexError:\n",
    "        \"The regexp is matching too many JSON entries, please take a look at \" + str(link)\n",
    "    \n",
    "    biz_dict[biz_name] = json.loads(re.sub(\", \\\"geoquad\\\".*\",'', match) + '}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Output JSON file of all the business details\n",
    "with open('biz_details_2.json', 'w') as outfile:\n",
    "    json.dump(biz_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biz_json = json.load(open(\"/Users/robertsonwang/Desktop/Python/Yelp/Yelp_scrapper/biz_details.json\"))\n",
    "agg_dict = dict(biz_json, **biz_dict)\n",
    "with open('biz_details_agg.json', 'w') as outfile:\n",
    "    json.dump(agg_dict, outfile)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
